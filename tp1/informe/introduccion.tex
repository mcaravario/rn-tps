\section{Introducción}


\section{Modo de uso y requerimientos}
Para correr este programa es necesario contar con Python 3 instalado junto a los paquetes Numpy y Pandas. Ambos paquetes pueden descargarse a traves
de la herramienta pip de python mediante el comando
\begin{verbatim}
  sudo pip3 install pandas
  sudo pip3 install numpy
\end{verbatim}
En caso de no tener instalada la herramienta pip, se la puede instalar con el comando
\begin{verbatim}
  sudo apt-get install python3-pip
\end{verbatim}

Para utilizar el programa debe posicionarse en la carpeta correspondiente al ejercicio que se desea correr. Luego se debe ejecutar el siguiente comando
\begin{verbatim}
  python3 ej --units unidades --act_units af -t tm -n eta -e epochs -a a -b b --alpha alpha
          --batch_size bs --training-prop tp --random-funct rf --normalize-input
          --no-normalize-input --normalize-output  --no_normalize-output
          --test --train --db
\end{verbatim}

en donde:
\begin{itemize}
  \item \textbf{ej}: es el ejericio que se va a correr, sus valores pueden ser {ej1-runner.py, ej2-runner.py} desde la carpeta arriba de tp1.
  \item \textbf{unidades}: es la cantidad de unidades por capa, separados por un guión, por ejemplo 10-20-1
  \item \textbf{af}: son las funciones de activacion que se utilizaran para cada capa intermedia de la red. Sus valores pueden ser:
	  \begin{itemize} 
	      \item s: Funcion signo
	      \item t: Tangente hiperbolica
          \item l: Sigmoidea
          \item r: ReLu
          \item i: Funcion identidad
       \end{itemize}
	   Las funciones deben ir separadas por un guion, por ejemplo l-t-s.
  \item \textbf{tm}: es el modo de entrenamiento, sus valores pueden ser {stochastic, online, batch, mini\_batch}. En caso de ser mini\_batch la opcion seleccionada se debera
            proveer el tamaño del batch a utilizar mediante la opcion --batch\_size bs, en donde bs será el tamaño en cuestion.
  \item \textbf{eta}: es el coeficiente de entrenamiento $\eta$ que se utilizará en el entrenamiento
  \item \textbf{epochs}: es la cantidad de epocas que se utilizaran para el entrenamiento
  \item \textbf{a}: es el coeficiente a correspondiente al correspondiente parametro adaptativo de entrenamiento
  \item \textbf{b}: es el coeficiente b correspondiente al correspondiente parametro adaptativo de entrenamiento
  \item \textbf{alpha}: es un parametro opcional que se utiliza en caso de querer utilizar la optimizacion de momentum para el algoritmo de BackPropagation. Corresponde al $\alpha$
                correspondiente.
  \item \textbf{tp}: es un parametro opcional que representa la proporcion correspondiente del set de datos que se utilizara como datos de entrenamiento,
            mientras que el resto se utilzara como datos de validacion. El valor de tp provisto debe ser 0 < tp < 1.
  \item \textbf{rf}: es un parametro opcional que selecciona el valor de la funcion random que se utilizara para la inicializacion de los pesos en la matriz de pesos de la red.
            Sus valores pueden ser {normal, uniform}
  \item \textbf{--test}: es un parametro opcional que indica que se utilizara la mejor red entrenada por el grupo para testear sobre el set de datos que se pasan en el parametro
                        --db. Es decir que evaluara el set de datos con la mejor red entrenada.
  \item \textbf{--train}: es un parametro opcional que especifica que se entrenara la red pasada como parametro y se utilizara el set de datos pasados en el parametro --db
                        como conjunto de datos de entrenamiento.
  \item \textbf{--db}: es un parametro opcional que especifica la base de datos que se utilizara ya sea para entrenar una nueva red si esta activada la opcion --train, o
                        para testear la mejor red obtenida en caso de que este el parametro --test.
  \item \textbf{--no-normalize-input}: es un parametro opcional que especifica que no se normalice la entrada
  \item \textbf{--normalize-input}: es un parametro opcional que especifica que se normalice la entrada
  \item \textbf{--normalize-output}: es un parametro opcional que especifica que se normalice la salida
  \item \textbf{--no-normalize-output}: es un parametro opcional que especifica que no se normalice la salida
\end{itemize}

En caso de querer consultar el modo de uso manualmente puede hacerse mediante el comando
\begin{verbatim}
    sudo python3 ej -h
\end{verbatim}
en donde ej puede ser {ej1-runner.py, ej2-runner.py} desde la carpeta arriba de tp1.
%
% -t {stochastic,online,batch,mini_batch}, --training-mode {stochastic,online,batch,mini_batch}
%                        Modo de entrenamiento
%  -n ETA, --eta ETA
%  -e EPOCHS, --epochs EPOCHS
%  --alpha ALPHA
%  -a A, --a A
%  -b B, --b B
%  --batch_size BATCH_SIZE
%  --training-prop TRAINING_PROP
%  --normalize-input
%  --no-normalize-input
%  --normalize-output
%  --no_normalize-output
%  --random-funct {normal,uniform}

\newpage
