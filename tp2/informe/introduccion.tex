\section{Introducción}

En este trabajo se implementaron técnicas de aprendizaje no supervisado para
clasificar documentos en distintas categorías. Para este cometido se entrenaron
no supervisadamente diversos tipos de redes neuronales basados en Aprendizaje
Hebbiano y Redes Auto-organizadas. Cada documento fue preprocesado con el
esquema Bag of Words para obtener vector de 850 componentes que indica en la i-ésima
coordenada la frecuencia de la iésima palabra del diccionario en el documento.
Debido a la alta dimensionalidad del espacio de este problema primero se buscó
disminuir los datos a un espacio de dimensionalidad menor y más tratable que
capturara aproximadamente la misma información con el Análisis de Componentes
Principales basado en Aprendizaje Hebbiano.


\section{Modo de uso y requerimientos}
Para correr este programa es necesario contar con \textbf{Python 3} (No funcionará con python2.7) instalado junto a los paquetes Numpy, Pandas y Scikit-Learn. Estos paquetes pueden descargarse a través
de la herramienta pip de python mediante el comando
\begin{verbatim}
  sudo pip3 install pandas
  sudo pip3 install numpy
  sudo pip3 install sklearn
\end{verbatim}
En caso de no tener instalada la herramienta pip, se la puede instalar con el comando
\begin{verbatim}
  sudo apt-get install python3-pip
\end{verbatim}

Para utilizar el programa realizado para el ejercicio 1 debe posicionarse en la carpeta tp2 Luego se debe ejecutar el siguiente comando
\begin{verbatim}
  python3 ej1.py --test --train --db db --epochs epocas
                --test_size ts --eta eta --rule r --normalize
                --no-normalize --output output
\end{verbatim}

en donde:
\begin{itemize}
  \item \textbf{--test}: es un parámetro opcional que indica que se utilizara la mejor red entrenada por el grupo para testear sobre el set de datos que se pasan en el parámetro
  --db. Es decir que evaluara el set de datos con la mejor red entrenada.
  \item \textbf{--train}: es un parámetro opcional que especifica que se entrenara la red pasada como parámetro y se utilizara el set de datos pasados en el parámetro --db
  como conjunto de datos de entrenamiento.
  \item \textbf{--db}: es un parámetro opcional que especifica la base de datos que se utilizara ya sea para entrenar una nueva red si esta activada la opción --train, o
  para testear la mejor red obtenida en caso de que este el parámetro --test.
  \item \textbf{epocas}: es la cantidad de épocas que se utilizaran para el entrenamiento
  \item \textbf{ts}: es el porcentaje de datos de la base data que se utilizara como datos de testing.
  \item \textbf{eta}: es el coeficiente de entrenamiento $\eta$ que se utilizará en el entrenamiento
  \item \textbf{rule}: es la regla que se utilizara para realizar la reducción de dimensionalidad. Sus valores pueden ser {"oja", "sanger"}
  \item \textbf{--normalize}: es un parámetro opcional que especifica que se normalice la entrada correspondiente.
  \item \textbf{--no-normalize}: es un parámetro opcional que especifica que no se normalice la entrada correspondiente.
  \item \textbf{output}: es un parámetro opcional que indica el archivo en el que se guardan los pesos.
\end{itemize}

Para utilizar el programa correspondiente al ejercicio 2, debe ejecutarse el siguiente comando
\begin{verbatim}
  python3 ej2.py --test --train --db db --preprocess --no-preprocess
                --epochs epocas --test_size ts --rows r --cols c --eta0 eta0
                --sigma0 sigma0 --tao0 tao0 --tao1 tao1 --output output
                --normalize --no-normalize --components comp
\end{verbatim}

en donde:
\begin{itemize}
  \item \textbf{--test}: es un parámetro opcional que indica que se utilizara la mejor red entrenada por el grupo para testear sobre el set de datos que se pasan en el parámetro
  --db. Es decir que evaluara el set de datos con la mejor red entrenada.
  \item \textbf{--train}: es un parámetro opcional que especifica que se entrenara la red pasada como parámetro y se utilizara el set de datos pasados en el parámetro --db
  como conjunto de datos de entrenamiento.
  \item \textbf{--db}: es un parámetro opcional que especifica la base de datos que se utilizara ya sea para entrenar una nueva red si esta activada la opción --train, o
  para testear la mejor red obtenida en caso de que este el parámetro --test.
  \item \textbf{--preprocess}: es un parámetro opcional que especifica que se normalice la entrada correspondiente.
  \item \textbf{--no-preprocess}: es un parámetro opcional que especifica que no se normalice la entrada correspondiente.
  \item \textbf{epocas}: es la cantidad de épocas que se utilizaran para el entrenamiento
  \item \textbf{ts}: es el porcentaje de datos de la base data que se utilizara como datos de testing.
  \item \textbf{r}: es la cantidad de filas que tendra la grilla del mapa auto-organizado
  \item \textbf{c}: es la cantidad de columnas que tendra la grilla del mapa auto-organizado
  \item \textbf{eta0}: es el coeficiente de entrenamiento $\eta$ inicial
  \item \textbf{sigma0}: es el coeficiente $\sigma$ inicial
  \item \textbf{tao0}: es el factor de dilatacion del tiempo (eta)
  \item \textbf{tao1}: es el factor de dilatacion del tiempo (sigma)
  \item \textbf{output}: es un parámetro opcional que indica el archivo en el que se guardan los pesos.
  \item \textbf{--normalize}: es un parámetro opcional que especifica que se normalice la entrada correspondiente.
  \item \textbf{--no-normalize}: es un parámetro opcional que especifica que no se normalice la entrada correspondiente.
  \item \textbf{comp}: es un parámetro opcional que especifica la cantidad de componentes a las que se quiere reducir en caso  de usar preprocesamiento de la entrada (por defecto es 9).

\end{itemize}

En caso de querer consultar el modo de uso manualmente puede hacerse mediante el comando
\begin{verbatim}
    sudo python3 ej -h
\end{verbatim}
en donde ej puede ser {ej1.py, ej2.py} dentro de la carpeta tp2.

\newpage
