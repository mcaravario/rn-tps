\section{Ejercicio 2}

\subsection{Introducción}
Este ejercicio consistio en crear un modelo de mapeo de caracteristicas auto-organizadas con el objetivo de clasificar documentos. El mapa
auto-organizado que se utilizo fue una grilla bidimensional de 10 filas y 10 columnas. El objetivo de este ejercicio es el de observar espacialamente
en la grilla las distintas clases de los datos.

Para el entrenamiento se utilizo la siguiente formula para obtener la neurona ganadora $k^*$:
  \[
  k^* = \argmin_{i,j} \lvert\lvert x-w_{i,j} \rvert\rvert
  \]

La regla de entrenamiento en cada patron luego de obtener la neurona ganadora es

\begin{equation}
	\Delta W = \eta_t \cdot h_{k^*}(i,j) \cdot (X^{\mu}-W_{i,j})
\end{equation}
donde h es una función que mapea la distancia entre dos neuronas
según la distribución normal.
\[
	h_{k^*}(i, j) = e^{-\frac{d_{k^*}(i,j)^2}{2}}
\]
con $d_{k^*}(i,j)$ es la típica distancia euclideana entre los puntos de la grilla (i,j) y
la neurona ganadora $k^*$ escalada por un factor de $1/\sigma_t$, ie.
$ d_{k^*}(i,j) = \frac{\lvert \lvert (i,j)-k^* \rvert \rvert}{\sigma_t} $

Las funciones de enfriamiento de $\eta$ y $\sigma$ que se utilizaron 
en cada iteración $t$ fueron las siguientes:
\[
  \begin{array}{ccc}
    \eta_t & = & \eta_0 \cdot e^{\frac{-x}{\tau_1}} \\
    \sigma_t & = & \sigma_0 \cdot e^{\frac{-x}{\tau_2}} \\
  \end{array}
\]

Este enfriamiento de las variables $\eta$ y $\sigma$ permiten ir disminuyendo
el nivel de aprendizaje y el area de vecindad respectivamente de cada neurona
para que la red a traves del tiempo pueda converger a un estado final estable.


\subsection{Resultados}
\subsubsection{Elección de los parametros}
\begin{itemize}
	\item $\eta_0$: debe eligirse grande de forma tal que al inicio
puedan ser realizados cambios bruscos por la red para 
poder organizarse inicialmente.

	\item $\sigma_0$: Inicialmente tiene que ser grande para que el área
de vecindad pueda abarcar a todos los nodos con esto alcanzaría aproximadamente
con el tamaño del díametro de la grilla

\[
	diam = \sqrt{rows^2+cols^2}
\]
	\item $\tau_1$ y $\tau_2$ deben elegirse de forma tal que al terminar
	todas las iteraciones los valores de $\eta$ y $\sigma$ alcancen
	una pequeña proporcion de los $\eta$ y $\sigma$ iniciales.

	La cantidad de iteraciones totales es $epochs \cdot training\_size $.
	Entonces si se quiere al final del entrenamiento que $\eta(t) \in (\eta_{f_l}, \eta_{f_u})$.
	Debe cumplirse que

	\[ \frac{t}{ln(\frac{\eta_0}{\eta_{f_l}})} < \tau_{1} < \frac{t}{ln(\frac{\eta_0}{\eta_{f_u}})} \]

	De igual manera si se quiere que $\sigma(t) \in (\eta_{f_l}, \eta_{f_u})$. Debe cumplirse que

	\[ \frac{t}{ln(\frac{\sigma_0}{\sigma_{f_l}})} < \tau_{2} < \frac{t}{ln(\frac{\sigma_0}{\sigma_{f_u}})} \]

	En las experimentaciones con las formulas anteriores se buscó que el $\eta$ final este entre 0.001 y 0.002.
	y que el $\sigma$ final termine entre 0.1 y 0.05.

\end{itemize}

Por lo anteriormente explicado para el entrenamiento se utilizaron los siguientes parametros:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% AGREGAR PARAMETROS
\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    filas & columnas & epochs & $\eta_0$ & $\sigma_0$ & $\tau_1$ & $\tau_2$ & preprocess & componentes \\
    \hline
	10 & 10 & 100 & 0.1 & 16 & 1300 & 1100 & NO & \ \\
    \hline
	10 & 10 & 100 & 0.1 & 16 & 1300 & 1100 & SI & 3 \\
    \hline
	10 & 10 & 100 & 0.1 & 16 & 1300 & 1100 & SI & 9 \\
    \hline
	25 & 25 & 100 & 0.1 & 36 & 1300 & 1100 & NO & \  \\
    \hline
	25 & 25 & 100 & 0.1 & 36 & 1300 & 1100 & SI & 9  \\
    \hline
  \end{tabular}
\end{center}

Para la visualizacion de los resultados se realizo un grafico que por cada
muestra del conjunto de entrenamiento con su correspondiente etiqueta, se
calculo cual fue la neurona ganadora. Luego se calculo por cada neurona cual
fue la etiqueta que mas la activo y se la coloreo en base a esa categoria.  Los
resultados obtenidos fueron los siguientes

\subsection{Conclusión}
